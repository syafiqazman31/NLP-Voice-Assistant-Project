# ğŸ›’ Grocery & Pantry Assistant

**Course:** Natural Language Processing (NLP)  
**Project Theme:** AI Voice Assistant  
**Team:** [Your Team Name / Members]

---

## ğŸ“– Project Overview

The **Grocery & Pantry Assistant** is a local, voice-activated AI system designed to track what you are running out of and build shopping lists automatically .

The system listens to your voice commands to add or remove items from your digital pantry. It uses a local Large Language Model (Llama 3) to understand natural language, categorize items, and even suggest recipes based on the ingredients you currently have in stock .

### âœ¨ Key Features

- **ğŸ—£ï¸ Voice-Activated:** Hands-free operation using a "Push-to-Talk" interface .
- **ğŸ›’ Smart Inventory:** Adds and removes multiple items at once (e.g., _"Add chicken, eggs, and milk"_).
- **ğŸ§  Local Intelligence:** Runs completely offline using **Ollama (Llama 3)**, ensuring privacy and zero cloud costs .
- **ğŸ‘¨â€ğŸ³ Recipe Suggestions:** Suggests dishes you can cook based _strictly_ on your current inventory.
- **ğŸ’¾ Auto-Categorization:** Uses a local dataset to categorize items (e.g., "Apple" â†’ "Produce") .
- **ğŸ”Š Voice Feedback:** Confirms actions and reads recipes aloud using text-to-speech .

---

## ğŸ› ï¸ System Architecture

1.  **Input:** User speaks into the microphone via the Streamlit interface.
2.  **STT (Speech-to-Text):** Google Speech Recognition converts audio to text .
3.  **Processing (Logic Layer):**
    - Python parses the text.
    - **LLM (Llama 3):** Analyzes intent (Add/Remove/Recipe) and extracts entities.
    - **Database:** Updates `pantry.txt` and queries `grocery_dataset.json` .
4.  **Output:**
    - **TTS (Text-to-Speech):** `pyttsx3` reads the response aloud .
    - **GUI:** Streamlit updates the pantry list visually in real-time.

---

## ğŸš€ How to Run Locally

### Prerequisites

- Python 3.10+
- [Ollama](https://ollama.com/) installed and running.
- Model downloaded: `ollama run llama3`

### Installation Steps

1.  **Clone the repository:**
   
```bash
git clone https://github.com/syafiqazman31/NLP-Voice-Assistant-Project.git
 ```
2.  **Create a Virtual Environment (Recommended):**

    ```bash
    python -m venv venv
    # Windows:
    .\venv\Scripts\activate
    # Mac/Linux:
    source venv/bin/activate
    ```

3.  **Install Dependencies:**

    ```bash
    pip install -r requirements.txt
    ```

4.  **Run the Application:**
    Ensure Ollama is running in the background, then execute:
    ```bash
    streamlit run app.py
    ```

---

## ğŸ“‚ File Structure

- `app.py`: The main application code (Frontend + Backend).
- `grocery_dataset.json`: A simple knowledge base for item categorization .
- `pantry.txt`: The text file acting as the database for your grocery list.
- `requirements.txt`: List of Python libraries required to run the project .

---

## ğŸ¤– Technologies Used

- **LLM:** Meta Llama 3 (via Ollama)
- **Interface:** Streamlit
- **STT:** SpeechRecognition (Google API)
- **TTS:** pyttsx3
- **Language:** Python

---

## ğŸ¥ Deliverables

This repository contains the source code, requirements, and instructions required for the NLP Course Project .


